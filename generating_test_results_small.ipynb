{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.utilities import load_checkpoint\n",
    "from utils.metrics import IntegratedEvaluator\n",
    "import pyarrow.parquet as pq\n",
    "from omegaconf import OmegaConf\n",
    "from datasets.dataOps import create_ood_datasets, create_loc_ood_datasets, create_dataloaders\n",
    "from hydra.utils import instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A miscellaneous function to generate test results report\n",
    "def generate_txt_report(output_path: str,\n",
    "                        exp_name: str,\n",
    "                        ml_flow_run_name: str,\n",
    "                        summary: dict,\n",
    "                        per_variable_table: pd.DataFrame,\n",
    "                        last_timestep_table: pd.DataFrame,\n",
    "                        physical_metrics: dict\n",
    "                        ):\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        # Header\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(\"RESULTS REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"Experiment: {exp_name}\\n\")\n",
    "        f.write(f\"MLflow Run: {ml_flow_run_name}\\n\\n\")\n",
    "\n",
    "        # Summary\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(\"SUMMARY\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        for name, metric in summary.items():\n",
    "            f.write(f\"{name}: {metric}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Physical Metrics\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(\"PHYSICAL METRICS\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        for name, metric in physical_metrics.items():\n",
    "            f.write(f\"{name}: {metric}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Tables\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(\"TABLE: Per variable entire table\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(per_variable_table.to_string(index=True))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(\"TABLE: Last time step\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(last_timestep_table.to_string(index=True))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        # Tail\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(\"END OF REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c27e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary useful to for aesthehics in the report (row names)\n",
    "corr_variables = {\"Var_0\" : \"DVS\",\n",
    "                  \"Var_1\" : \"LAI\",\n",
    "                  \"Var_2\" : \"TAGP\",\n",
    "                  \"Var_3\" : \"TWSO\",\n",
    "                  \"Var_4\" : \"TWLV\",\n",
    "                  \"Var_5\" : \"TWST\",\n",
    "                  \"Var_6\" : \"TWRT\",\n",
    "                  \"Var_7\" : \"DMI\",\n",
    "                  \"Var_8\" : \"ASRC\",\n",
    "                  \"Var_9\" : \"GASS\",\n",
    "                  \"Var_10\": \"MRES\"\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"208516e27b7f4b59a28c9f7dbeb173cf\" # Put here your running id for the target experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "client = mlflow.client.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b8f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = client.get_run(RUN_ID).to_dictionary()\n",
    "print(dico[\"data\"][\"tags\"][\"exp_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dico[\"info\"][\"artifact_uri\"].removeprefix(\"file://\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico[\"info\"][\"artifact_uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(os.path.join(dico[\"info\"][\"artifact_uri\"].removeprefix(\"file://\"), \"config_exp.yaml\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "data = {}\n",
    "for array in [\"static_data\", \"before_ts\", \"after_ts\", \"target_ts\", \"mask_target\", \"cat_dicos\"]:\n",
    "    with open(f\"{cfg.raw_data_folder + array}.pkl\", \"rb\") as f:\n",
    "        data[array] = pickle.load(f)\n",
    "table = pq.read_table(cfg.raw_data_folder + cfg.info_ts_file)\n",
    "ids = table.to_pandas().index.to_list()\n",
    "list_unic_cat = [len(dico.keys()) for dico in data[\"cat_dicos\"].values()]\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, ood_dataset = create_loc_ood_datasets(ids=ids,\n",
    "                                                            static_data=data[\"static_data\"],\n",
    "                                                            before_ts=data[\"before_ts\"],\n",
    "                                                            after_ts=data[\"after_ts\"],\n",
    "                                                            target_ts=data[\"target_ts\"],\n",
    "                                                            mask_target=data[\"mask_target\"],\n",
    "                                                            train_size=cfg.training.train_size,\n",
    "                                                            val_size=cfg.training.val_size,\n",
    "                                                            raw_data_folder=cfg.raw_data_folder,\n",
    "                                                            means_and_stds_path=cfg.means_and_stds_path,\n",
    "                                                            entire_bool=False\n",
    "                                                           )\n",
    "\n",
    "_, test_loader, ood_loader = create_dataloaders(train_dataset,\n",
    "                                                test_dataset,\n",
    "                                                ood_dataset,\n",
    "                                                batch_size=cfg.training.batch_size)\n",
    "\n",
    "encoder = instantiate(cfg.model.encoder,\n",
    "                        list_unic_cat=list_unic_cat).to(device)\n",
    "decoder = instantiate(cfg.model.decoder).to(device)\n",
    "\n",
    "optimizer = instantiate(cfg.training.optimizer,\n",
    "                        params = list(encoder.parameters()) + list(decoder.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dee91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/work_data/means_and_stds_small.pkl\", \"rb\") as f:\n",
    "    means_and_stds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"checkpoints/10_entire_physical_HardWiredBIG_60_eps/best_model.pth\")\n",
    "checkpoint = torch.load(dico[\"info\"][\"artifact_uri\"].removeprefix(\"file://\") + \"/best_model/best_model.pth\")\n",
    "\n",
    "load_checkpoint(checkpoint,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_hat_target = []\n",
    "    batch_hat_mask = []\n",
    "    batch_target = []\n",
    "    batch_mask = []\n",
    "    ids = []\n",
    "    for batch in test_loader:\n",
    "        ids.append(batch[\"id\"])\n",
    "        static_data_cat = batch[\"static_data_cat\"].to(device)\n",
    "        static_data_num = batch[\"static_data_num\"].to(device)\n",
    "        before_ts = batch[\"before_ts\"].to(device)\n",
    "        after_ts = batch[\"after_ts\"].to(device)\n",
    "        target_ts = batch[\"target_ts\"].to(device)\n",
    "        mask_target = batch[\"mask_target\"].to(device)\n",
    "\n",
    "        latent, x_t = encoder(static_data_num, static_data_cat, before_ts)\n",
    "        h_t = latent\n",
    "        generated_ts = [] \n",
    "        for t in range(after_ts.shape[1]):\n",
    "            output, h_t, h_output = decoder(x_t.unsqueeze(1),\n",
    "                                            h_t,\n",
    "                                            after_ts[:, t, :],\n",
    "                                            ar=True)\n",
    "            generated_ts.append(output)\n",
    "            x_t = output\n",
    "            \n",
    "        batch_hat_target.append((torch.stack(generated_ts, dim=1).to(\"cpu\") * means_and_stds[\"target_ts_std\"]) + means_and_stds[\"target_ts_mean\"])\n",
    "        batch_target.append((target_ts.to(\"cpu\") * means_and_stds[\"target_ts_std\"]) + means_and_stds[\"target_ts_mean\"])\n",
    "        batch_mask.append(mask_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_target[0].shape, batch_hat_target[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92172125",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_batch_hat_target = torch.cat(batch_hat_target, dim=0).to(\"cpu\")\n",
    "concat_batch_target = torch.cat(batch_target, dim=0).to(\"cpu\")\n",
    "concat_real_mask = torch.cat(batch_mask, dim=0).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ae0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the maximum value index\n",
    "\n",
    "cosa = abs((concat_batch_hat_target*concat_real_mask)-(concat_batch_target*concat_real_mask))\n",
    "\n",
    "x_flat = cosa.view(-1)\n",
    "\n",
    "# Get index of max value\n",
    "max_index = x_flat.argmax()\n",
    "\n",
    "# Convert flat index back to multi-dimensional index\n",
    "max_position = torch.unravel_index(max_index, cosa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ba7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "i = 21\n",
    "sns.lineplot(concat_batch_target[i][:,0].to(\"cpu\").numpy(), ax=ax[0, 0])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,0].to(\"cpu\").numpy(), ax=ax[0, 0])\n",
    "sns.lineplot(concat_real_mask[i][:,0].to(\"cpu\").numpy(), ax=ax[0, 0])\n",
    "sns.lineplot(concat_batch_target[i][:,1].to(\"cpu\").numpy(), ax=ax[0, 1])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,1].to(\"cpu\").numpy(), ax=ax[0, 1])\n",
    "sns.lineplot(concat_batch_target[i][:,2].to(\"cpu\").numpy(), ax=ax[1, 0])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,2].to(\"cpu\").numpy(), ax=ax[1, 0])\n",
    "sns.lineplot(concat_batch_target[i][:,3].to(\"cpu\").numpy(), ax=ax[1, 1])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,3].to(\"cpu\").numpy(), ax=ax[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = IntegratedEvaluator(y_true=concat_batch_target.numpy(),\n",
    "                                y_pred=concat_batch_hat_target.numpy(),\n",
    "                                mask=concat_real_mask.squeeze(-1).numpy()\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa25238",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=concat_batch_target.numpy()\n",
    "y_pred=concat_batch_hat_target.numpy()\n",
    "mask=concat_real_mask.squeeze(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60752d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_var_table = evaluator.to_dataframe()\n",
    "per_var_table.index = per_var_table.index.to_series().map(corr_variables)\n",
    "last_ts_table = evaluator.evaluate_last_timestep()\n",
    "last_ts_table.index = last_ts_table.index.to_series().map(corr_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ef06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(name=\"results_reports/\", exist_ok=True)\n",
    "generate_txt_report(output_path= \"results_reports/\" + \\\n",
    "                    dico[\"data\"][\"tags\"][\"exp_name\"].split(\"_\")[0] + \"_\" \\\n",
    "                    + RUN_ID + \"_test_results_report.txt\",\n",
    "                    exp_name=dico[\"data\"][\"tags\"][\"exp_name\"],\n",
    "                    ml_flow_run_name=RUN_ID,\n",
    "                    summary=evaluator.summary(),\n",
    "                    per_variable_table=per_var_table,\n",
    "                    last_timestep_table=last_ts_table,\n",
    "                    physical_metrics={\"nothing\":\"nothing\"}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be36d7",
   "metadata": {},
   "source": [
    "# OOD Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_hat_target = []\n",
    "    batch_hat_mask = []\n",
    "    batch_target = []\n",
    "    batch_mask = []\n",
    "    ids = []\n",
    "    for batch in ood_loader:\n",
    "        ids.append(batch[\"id\"])\n",
    "        static_data_cat = batch[\"static_data_cat\"].to(device)\n",
    "        static_data_num = batch[\"static_data_num\"].to(device)\n",
    "        before_ts = batch[\"before_ts\"].to(device)\n",
    "        after_ts = batch[\"after_ts\"].to(device)\n",
    "        target_ts = batch[\"target_ts\"].to(device)\n",
    "        mask_target = batch[\"mask_target\"].to(device)\n",
    "\n",
    "        latent, x_t = encoder(static_data_num, static_data_cat, before_ts)\n",
    "        h_t = latent\n",
    "        generated_ts = [] \n",
    "        for t in range(after_ts.shape[1]):\n",
    "            output, h_t, h_output = decoder(x_t.unsqueeze(1),\n",
    "                                            h_t,\n",
    "                                            after_ts[:, t, :],\n",
    "                                            ar=True)\n",
    "            generated_ts.append(output)\n",
    "            x_t = output\n",
    "            \n",
    "        batch_hat_target.append((torch.stack(generated_ts, dim=1).to(\"cpu\") * means_and_stds[\"target_ts_std\"]) + means_and_stds[\"target_ts_mean\"])\n",
    "        batch_target.append((target_ts.to(\"cpu\") * means_and_stds[\"target_ts_std\"]) + means_and_stds[\"target_ts_mean\"])\n",
    "        batch_mask.append(mask_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4467fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_batch_hat_target = torch.cat(batch_hat_target, dim=0).to(\"cpu\")\n",
    "concat_batch_target = torch.cat(batch_target, dim=0).to(\"cpu\")\n",
    "concat_real_mask = torch.cat(batch_mask, dim=0).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ce36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "i = 6\n",
    "sns.lineplot(concat_batch_target[i][:,0].to(\"cpu\").numpy(), ax=ax[0, 0])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,0].to(\"cpu\").numpy(), ax=ax[0, 0])\n",
    "sns.lineplot(concat_real_mask[i][:,0].to(\"cpu\").numpy(), ax=ax[0, 0])\n",
    "sns.lineplot(concat_batch_target[i][:,1].to(\"cpu\").numpy(), ax=ax[0, 1])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,1].to(\"cpu\").numpy(), ax=ax[0, 1])\n",
    "sns.lineplot(concat_batch_target[i][:,2].to(\"cpu\").numpy(), ax=ax[1, 0])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,2].to(\"cpu\").numpy(), ax=ax[1, 0])\n",
    "sns.lineplot(concat_batch_target[i][:,3].to(\"cpu\").numpy(), ax=ax[1, 1])\n",
    "sns.lineplot(concat_batch_hat_target[i][:,3].to(\"cpu\").numpy(), ax=ax[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = IntegratedEvaluator(y_true=concat_batch_target.numpy(),\n",
    "                                y_pred=concat_batch_hat_target.numpy(),\n",
    "                                mask=concat_real_mask.squeeze(-1).numpy()\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_var_table = evaluator.to_dataframe()\n",
    "per_var_table.index = per_var_table.index.to_series().map(corr_variables)\n",
    "\n",
    "last_ts_table = evaluator.evaluate_last_timestep()\n",
    "last_ts_table.index = last_ts_table.index.to_series().map(corr_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_txt_report(output_path= \"results_reports/\" + dico[\"data\"][\"tags\"][\"exp_name\"].split(\"_\")[0] + \"_\" +RUN_ID + \"_OOD_results_report.txt\",\n",
    "                    exp_name=dico[\"data\"][\"tags\"][\"exp_name\"],\n",
    "                    ml_flow_run_name=RUN_ID,\n",
    "                    summary=evaluator.summary(),\n",
    "                    per_variable_table=per_var_table,\n",
    "                    last_timestep_table=last_ts_table,\n",
    "                    physical_metrics={\"nothing\":\"nothing\"}\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winn_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
